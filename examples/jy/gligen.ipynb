{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionGLIGENTextImagePipeline\n",
    "from diffusers.utils import load_image\n",
    "\n",
    "# Insert objects described by image at the region defined by bounding boxes\n",
    "pipe = StableDiffusionGLIGENTextImagePipeline.from_pretrained(\n",
    "    \"anhnct/Gligen_Inpainting_Text_Image\", torch_dtype=torch.float16\n",
    ")\n",
    "pipe = pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "input_image = load_image(\n",
    "    \"https://hf.co/datasets/huggingface/documentation-images/resolve/main/diffusers/gligen/livingroom_modern.png\"\n",
    ")\n",
    "prompt = \"a backpack\"\n",
    "boxes = [[0.2676, 0.4088, 0.4773, 0.7183]]\n",
    "phrases = None\n",
    "gligen_image = load_image(\n",
    "    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/gligen/backpack.jpeg\"\n",
    ")\n",
    "\n",
    "images = pipe(\n",
    "    prompt=prompt,\n",
    "    gligen_phrases=phrases,\n",
    "    gligen_inpaint_image=input_image,\n",
    "    gligen_boxes=boxes,\n",
    "    gligen_images=[gligen_image],\n",
    "    gligen_scheduled_sampling_beta=1,\n",
    "    output_type=\"pil\",\n",
    "    num_inference_steps=50,\n",
    ").images\n",
    "\n",
    "images[0].save(\"./gligen-inpainting-text-image-box.jpg\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Generate an image described by the prompt and\n",
    "# insert objects described by text and image at the region defined by bounding boxes\n",
    "pipe = StableDiffusionGLIGENTextImagePipeline.from_pretrained(\n",
    "    \"anhnct/Gligen_Text_Image\", torch_dtype=torch.float16\n",
    ")\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "prompt = \"a flower sitting on the beach\"\n",
    "boxes = [[0.0, 0.09, 0.53, 0.76]]\n",
    "phrases = [\"flower\"]\n",
    "gligen_image = load_image(\n",
    "    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/gligen/pexels-pixabay-60597.jpg\"\n",
    ")\n",
    "\n",
    "images = pipe(\n",
    "    prompt=prompt,\n",
    "    gligen_phrases=phrases,\n",
    "    gligen_images=[gligen_image],\n",
    "    gligen_boxes=boxes,\n",
    "    gligen_scheduled_sampling_beta=1,\n",
    "    output_type=\"pil\",\n",
    "    num_inference_steps=50,\n",
    ").images\n",
    "\n",
    "images[0].save(\"./gligen-generation-text-image-box.jpg\")\n",
    "\n",
    "# Generate an image described by the prompt and\n",
    "# transfer style described by image at the region defined by bounding boxes\n",
    "pipe = StableDiffusionGLIGENTextImagePipeline.from_pretrained(\n",
    "    \"anhnct/Gligen_Text_Image\", torch_dtype=torch.float16\n",
    ")\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "prompt = \"a dragon flying on the sky\"\n",
    "boxes = [[0.4, 0.2, 1.0, 0.8], [0.0, 1.0, 0.0, 1.0]]  # Set `[0.0, 1.0, 0.0, 1.0]` for the style\n",
    "\n",
    "gligen_image = load_image(\n",
    "    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/landscape.png\"\n",
    ")\n",
    "\n",
    "gligen_placeholder = load_image(\n",
    "    \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/diffusers/landscape.png\"\n",
    ")\n",
    "\n",
    "images = pipe(\n",
    "    prompt=prompt,\n",
    "    gligen_phrases=[\n",
    "        \"dragon\",\n",
    "        \"placeholder\",\n",
    "    ],  # Can use any text instead of `placeholder` token, because we will use mask here\n",
    "    gligen_images=[\n",
    "        gligen_placeholder,\n",
    "        gligen_image,\n",
    "    ],  # Can use any image in gligen_placeholder, because we will use mask here\n",
    "    input_phrases_mask=[1, 0],  # Set 0 for the placeholder token\n",
    "    input_images_mask=[0, 1],  # Set 0 for the placeholder image\n",
    "    gligen_boxes=boxes,\n",
    "    gligen_scheduled_sampling_beta=1,\n",
    "    output_type=\"pil\",\n",
    "    num_inference_steps=50,\n",
    ").images\n",
    "\n",
    "images[0].save(\"./gligen-generation-text-image-box-style-transfer.jpg\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}